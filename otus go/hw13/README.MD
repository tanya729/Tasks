# Calendar Project

## Part 1
Создать интерфейс хранилища событий, состоящий из методов для работы с ним:  
- добавление событий в хранилище  
- удаление событий из хранилища  
- изменение событий в хранилище  
- листинг событий  
- пр. на усмотрение студента  
Создать объекты ошибок (error sentinels) соответствующие бизнес ошибкам, например ErrDateBusy - данное время уже занято другим событием.  
Создать структуру, реализующую интерфейс выше логикой хранения событий в памяти (т.е. просто складывать объекты в мапы/слайсы).  
Реализовать unit-тесты проверяющие работу хранилища (в частности ошибки).  
Создать структуру календаря, использующую в себе хранилище. Календарь конструируется в main (в последствии он превратится в GRPC/HTTP-листенер).  

## Part 2
Необходимо доработать код сервиса "Календарь" из предыдущего задания, добавив в него:  

* Обработку аргументов командной строки  
* Чтение файла конфигурации (параметр --config в командной строке)  
* Создание логгеров и настройка уровня логирования  
* Создание и запуск hello-world web-сервера  

Параметры, передаваемые через аргументы командной строки:  
* --config - путь к конфигу  

Параметры, которые должны быть в конфиге:  
* http - ip и port на котором должен слушать web-сервер  
* log_file - путь к файлу логов  
* log_level - уровень логирования (error / warn / info / debug)  

## Part 3
GRPC сервис
Цель: Создать GRPC API для сервиса календаря Тех. задание: https://github.com/OtusTeam/Go/blob/master/project-calendar.md Цель данного занятия: отработка навыков работы с GRPC, построение современного API.  
Создать отдельную директорию для Protobuf спек.  
Создать Protobuf спеки с описанием всех методов API, их объектов запросов и ответов.  
Т.к. объект Event будет использоваться во многих ответах разумно выделить его в отдельный message.  
Создать отдельный директорию для кода GRPC сервера  
Сгенерировать код GRPC сервера на основе Protobuf спек (скрипт генерации сохранить в репозиторий).  
Написать код, связывающий GRPC сервер с методами доменной области.  
Запуск сервера: `cd grpc && go run server/server.go -config=../config/application.yml`  
Запуск клиента: `cd grpc && go run client/client.go -config=../config/application.yml`  
Генерация кода на основе спек: `protoc -I api/ api/calendar.proto --go_out=plugins=grpc:internal/pkg/`  

## Part 4
Работа с базами данных  
Цель: Обеспечить сохранение событий календаря в СУБД Тех. задание: https://github.com/OtusTeam/Go/blob/master/project-calendar.md Цель данного занятия: отработка навыков работы СУБД, SQL, пакетами database/sql и github.com/jmoiron/sqlx  
Установить базу данных (например postgres) локально (или сразу в Docker, если знаете как)  
Создать базу данных и пользователей для проекта календарь  
Создать схему данных (таблицы, индексы) в виде отдельного SQL файла и сохранить его в репозиторий  
В проекте календарь создать отдельный пакет, отвечающий за сохранение моделей в СУБД  
Настройки подключения к СУБД вынести в конфиг проекта  
Изменить код приложения так, что бы обеспечить сохранение событий в СУБД  
Запуск бд: `docker-compose up`  

## Part 5
Работа с очередями  
Цель: Реализовать "напоминания" о событиях с помощью RabbitMQ. Тех. задание: https://github.com/OtusTeam/Go/blob/master/project-calendar.md Цель данного занятия: отработка навыков работы с RabbitMQ и очередями вообще.  
Установить локально очередь сообщений RabbitMQ (можно сразу в Docker если знаете как)  
Создать процесс (scheduler), который периодически сканирует основную базу данных, выбирая события о которых нужно напомнить.  
При запуске процесс должен подключаться к RabbitMQ и создавать все необходимые структуры (топики) в ней.  
Процесс должен выбирать сообытия для которых следует отправить уведомление, сериализовать их (например в JSON) и складывать в очередь.  
Создать процесс (sender), который читает сообщения из очереди и шлет уведомления.  
Непосредственно отправку делать не нужно - можно просто выводить сообщения в STDOUT.  
Запуск БД и Rabbit: `docker-compose up`

## Part 6
Доработка сервиса  
Цель: Данное ДЗ посвящено доработки кода. Новые навыки не отрабатываются. Важно довести проект до рабочего состояния, разделив его на отдельные сервисы.  
В результате компиляции проекта должно получаться 3 отдельных исполняемых файла (по одному на микросервис).  
Пример разбиения сервисов  
- API
- Рассыльщик
- Планировщик  

Каждый из сервисов должен принимать путь файлу конфигурации:  
./calendar_api --config=/path/to/config.yaml  
./calendar_scheduler --config=/path/to/config.yaml  
./calendar_sender --config=/path/to/config.yaml  
Запуск БД и Rabbit: `docker-compose up`  
Сборка: `make build` 

## Part 7
Докеризация сервиса  
Цель: Цель домашнего задания: запустить все компоненты проекта в Docker Отрабатываются навыки работы с Docker и docker-compose  
Создать Dockerfile для каждого из микросервисов (api, scheduler, sender)  
Собрать образы и проверить их локальный запуск  
Создать docker-compose файл, который запускает PostgreSQL, RabbitMQ и все микросервисы вместе.  
Для PostgreSQL и RabbitMQ использовать официальные образы из dockerhub.  
Так же в docker-compose должен запускаться one-shot скрипт который применяет SQL миграции, создавая структуру СУБД.  
Для контейнера с API необходимо пробросить (expose) порт 8888 на хост-машину.   
Запуск: `cd deployment && docker-compose up`  

## Part 8
Интеграционное тестирование  
Цель: Цель данного домашнего задания: научиться писать интеграционные тесты к web-сервисам В данном ДЗ изучается BDD, язык Gherkin, отрабатываются навыки работы с BDD библиотекой github.com/DATA-DOG/godog И еще раз с docker-compose =)  
Создать отдельный пакет для интеграционных тестов  
Описать все бизнес-сценарии на языке Gherkin в *.feature файлах.  
Реализовать все шаги сценариев с использованием библиотеки Godog  
При этом шаги могут рассчитывать на то что запущены в docker-compose и знают hostname:port все сервисов.  
Создать docker-compose файл, поднимающий все сервисы проекта + контейнер с интеграционными тестами  
В Makefile добавить команду test, которая будет запускать интеграционные тесты (см -https://docs.docker.com/compose/reference/up/ -exit-code-from)  
Запуск: `make test`  

## Part 9
Мониторинг сервиса  
Обеспечить простейший мониторинг проекта с помощью prometheus  
Prometheus запустить в docker контейнере рядом с остальными сервисами.  
Для API сервиса необходимо измерять:  
* Requests per second  
* Latency  
* Коды ошибок  
* Все это в разделении по методам (использовать отдельный тэг prometheus для каждого метода API)  
Для баз данных:  
* Количество записей в таблице events (данные брать из pg_stat_user_tables)  
* Стандартные метрики базы: Transactions per second, количество подключений (использовать готовый exporter)    
Запуск `docker-compose up --build` после чего на 3000 порту будет доступна Grafana с настроенной панелью метрик  